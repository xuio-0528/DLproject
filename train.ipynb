{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1FbdUDdw78S6Ti40WqcA5qFlVBdu6X23X","authorship_tag":"ABX9TyMyM1iW7llRWJchVAhZOGwX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["cd /content/drive/MyDrive/DLproject/DLproject"],"metadata":{"id":"v1ywTF3bqCqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email 'sus5467@naver.com'"],"metadata":{"id":"ZKunTBTAqMlq","executionInfo":{"status":"ok","timestamp":1699626952298,"user_tz":-540,"elapsed":1129,"user":{"displayName":"시젯","userId":"02123276030050228638"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!git config --global user.name 'xuio-0528'"],"metadata":{"id":"8N_GxY5LqOHX","executionInfo":{"status":"ok","timestamp":1699626952618,"user_tz":-540,"elapsed":326,"user":{"displayName":"시젯","userId":"02123276030050228638"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["! git add ."],"metadata":{"id":"fx4SFB7IqcrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! git commit -m \"train 수정\""],"metadata":{"id":"YDPBPZSmqdqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! git push"],"metadata":{"id":"huoIYr9Rqep5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 개요\n","\n","어떤 유형의 프로젝트를 진행할 것인가?\n","### 후보군\n","1. prompt tuning\n","2. LoRA\n","3. small model 학습\n","\n","### 장단점\n","#### 1. prompt tuning\n","- prompt tuning의 경우 오랜 학습이 필요하지 않음\n","- 어떤 부분을 차용해서 해볼 것인지에 대한 고려가 필요하다.\n","\n","#### 2. LoRA\n","- 오랜 학습이 필요하지는 않음\n","- LoRA로 무엇을 학습시킬 것인지 고안하는 것이 중요\n","- 학습이 잘 되지 않을 수 있다는 위험성이 존재\n","\n","\n","#### 3. small model 학습\n","- 성능 상승이 거의 일어나기 어렵다.\n","- 별로 매력적이지 않음\n","\n","#### 번외\n","- 1번 2번 두 가지 모두 이용을 해보는 것도 좋은 선택지가 될 것 같다.\n","\n","### 다룰 모델들은?\n","1. 코드 생성 모델\n","2. reasoning model\n","\n","위의 두 모델 같은 경우에는 아무래도 정확도가 어느 정도 담보가 되어 있는 모델들이 좋다.\n","\n","코드 생성 모델의 경우 phi-1.5를 사용할 것 같다.\n","reasoning model의 경우 llama를 사용하는 것이 좋을 것 같다.\n","\n","그렇다면 LoRA로 무엇을 가르쳐볼까?\n","\n","일반적으로 우리는 prompt를 학습하거나 freeze시키는 등을 통해 embedding에서의 수정을 해보고자 한다.\n","\n","혹은 하나의 prompt만을 동일하게 사용하려는 것을 보인다.\n","예를 들어, let's think about step by step 등\n","\n","그렇다면 prompt를 동일하게 사용하는 것이 아니라 prompt를 적절하게 generate를 시켜줄 수는 없을까?\n","\n","text description을 요약 모델에 넣어주어 title 혹은 summary를 요약해준다.\n","\n","summary와 원래의 text description을 모델에 동시에 제공하고 그것을 토대로 학습.\n","\n","그렇다면 GAN처럼 원래의 loss와 prompt를 넣었을 때의 loss를 비교하고 loss가 최소화되는 방향으로 prompt를 regenerate시키는 방향..?\n","\n","학습을 위해서 discrim\n","\n"],"metadata":{"id":"OGqwxMEXp0_f"}},{"cell_type":"code","source":[],"metadata":{"id":"rq95ED4ip9_R","executionInfo":{"status":"ok","timestamp":1699626967189,"user_tz":-540,"elapsed":2575,"user":{"displayName":"시젯","userId":"02123276030050228638"}}},"execution_count":5,"outputs":[]}]}